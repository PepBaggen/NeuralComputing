{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1be1b2f55b62c0",
   "metadata": {},
   "source": [
    "# Food Classification with CNN - Building a Restaurant Recommendation System\n",
    "\n",
    "This assignment focuses on developing a deep learning-based food classification system using Convolutional Neural Networks (CNNs). You will build a model that can recognize different food categories and use it to return the food preferences of a user.\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement CNNs for image classification\n",
    "- Work with real-world food image datasets\n",
    "- Build a preference-detector system\n",
    "\n",
    "## Background: AI-Powered Food Preference Discovery\n",
    "\n",
    "The system's core idea is simple:\n",
    "\n",
    "1. Users upload 10 photos of dishes they enjoy\n",
    "2. Your CNN classifies these images into the 91 categories\n",
    "3. Based on these categories, the system returns the user's taste profile\n",
    "\n",
    "Your task is to develop the core computer vision component that will power this detection engine.\n",
    "\n",
    "You are given a training (\"train\" folder) and a test (\"test\" folder) dataset which have ~45k and ~22k samples respectively. For each one of the 91 classes there is a subdirectory containing the images of the respective class.\n",
    "\n",
    "## Assignment Requirements\n",
    "\n",
    "### Technical Requirements\n",
    "- Implement your own pytorch CNN architecture for food image classification\n",
    "- Use only the provided training dataset split for training\n",
    "- Train the network from scratch ; No pretrained weights can be used\n",
    "- Report test-accuracy after every epoch\n",
    "- Report all hyperparameters of final model\n",
    "- Use a fixed seed and do not use any CUDA-features that break reproducibility\n",
    "- Use Pytorch 2.6\n",
    "\n",
    "### Deliverables\n",
    "1. Jupyter Notebook with CNN implementation, training code etc.\n",
    "2. README file\n",
    "3. Report (max 3 pages)\n",
    "\n",
    "Submit your report, README and all code files as a single zip file named GROUP_[number]_NC2425_PA. The names and IDs of the group components must be mentioned in the README.\n",
    "Do not include the dataset in your submission.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1. Correct CNN implementation, training runs on the uni computers (computer rooms DM.0.07, DM.0.13, DM.0.17, DM.0.21) according to the README.MD instructions without ANY exceptions: 3pt\n",
    "2. Perfect 1:1 reproducibility on those machines: 1pt\n",
    "3. Very clear github-repo-style README.MD with instructions for running the code: 1pt\n",
    "4. Report: 1pt\n",
    "5. Model test performance on test-set: interpolated from 30-80% test-accuracy: 0-3pt\n",
    "6. Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt\n",
    "7. Bonus point: use an LLM (API) to generate short description / profile of preferences of the simulated user\n",
    "\n",
    "**The main reason why we mention the machines in the uni computer rooms is to make it clear to you how we will test your submissions and to make you aware that you can use these machines for working on your assignment if you do not have access to a computer with enough gpu. You do not have to use these machines for this assignment. Using the specified pytorch version, not enabling torch.backends.cuda.matmul.allow_tf32, setting fixed seeds and making sure your code doesn't use more than 8gb VRAM should allow you to fulfill the reproducibility criteria.**\n",
    "\n",
    "**(If there is anything unclear about this assignment please post your question in the Brightspace discussions forum or send an email)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52be6aa80281ab2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:00:38.470477Z",
     "start_time": "2025-04-23T21:00:38.460547Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc8f550a31afdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:00:39.626856Z",
     "start_time": "2025-04-23T21:00:39.608051Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"   # deterministic mode for GPU \n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c222e5c4ff1b26",
   "metadata": {},
   "source": [
    "# Loading the datasets\n",
    "The dataset is already split into a train and test set in the directories \"train\" and \"test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed23ce7b9cbfbf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T21:02:29.983221Z",
     "start_time": "2025-04-23T21:00:40.781180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Dataloader for train set...\n",
      "Making Dataloader for test set...\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "def img_to_tensor(path):\n",
    "    \"\"\"\n",
    "    Transforms image into standardized grayscale and normalized tensor\n",
    "    :param path: path to image\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")      # use color too\n",
    "    img = img.resize((224, 224))\n",
    "    arr = np.array(img, dtype=np.float32) / 255\n",
    "    x = torch.tensor(arr.transpose(2, 0, 1))   # (C,H,W)\n",
    "    return x\n",
    "\n",
    "# make dataloaders out of train and test splits to be able to pass them to the CNN\n",
    "# ---\n",
    "splits = {'train': None, 'test': None} # dictionary {directory name: DataLoader} for the train test split\n",
    "class_count = 0\n",
    "for split in splits.keys():\n",
    "    print(f\"Making Dataloader for {split} set...\")\n",
    "    images = []\n",
    "    ordered_labels = []\n",
    "    for folder in os.scandir(split): # iterate through the contents of the directory\n",
    "        if not folder.is_dir(): # make sure content is directory (could be .DS_Store file)\n",
    "            continue\n",
    "        class_count += 1\n",
    "        for image in os.scandir(folder):\n",
    "            ordered_labels.append(folder.name) # an image's parent folder name is its label\n",
    "            image_tensor = img_to_tensor(image)\n",
    "            images.append(image_tensor)\n",
    "\n",
    "    \n",
    "    # encode labels into numbers then convert label list to tensor\n",
    "    encoder = LabelEncoder()\n",
    "    ordered_labels = encoder.fit_transform(ordered_labels)\n",
    "    ordered_labels_tensor = torch.LongTensor(ordered_labels)\n",
    "\n",
    "    # make one tensor of all image tensors (like an array of images)\n",
    "    all_image_tensor = torch.stack(images)\n",
    "\n",
    "    # make torch dataloader out of images and labels tensors\n",
    "    dataset = TensorDataset(all_image_tensor, ordered_labels_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    splits[split] = dataloader\n",
    "print(\"success\")\n",
    "# ---\n",
    "train_loader = splits['train']\n",
    "test_loader  = splits['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bb30ae14ffa42",
   "metadata": {},
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4855a7fbfb90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN taken from practical on brightspace\n",
    "# needs further tweaking\n",
    "\n",
    "batch_size = 32 # 16: safe, 32: faster but might not run on every pc\n",
    "num_classes = class_count\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "class FoodCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),  # use RGB → in_channels=3\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                 # 3×224×224 → 32×112×112\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                 # 64×56×56\n",
    "        )\n",
    "\n",
    "        # compute flattened size once\n",
    "        dummy = torch.zeros(1, 3, 224, 224)\n",
    "        flat = self.features(dummy).numel()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c602d154e795a27",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "Implement your training process below. Report the test-accuracy after every epoch for the training run of the final model.\n",
    "\n",
    "Hint: before training your model make sure to reset the seed in the training cell, as otherwise the seed may have changed due to previous training runs in the notebook\n",
    "\n",
    "Note: If you implement automatic hyperparameter tuning, split the train set into train and validation subsets for the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9eb5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126 12.6\n",
      "True\n",
      "NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and use it if possible, run on CPU otherwise\n",
    "\n",
    "import torch\n",
    "print(torch.__version__, torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ff7d9d84c06f5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | test acc 72.78%\n",
      "epoch 02 | test acc 76.95%\n",
      "epoch 03 | test acc 76.55%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m---> 28\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(model(x), y)\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reset the seed in this cell\n",
    "def accuracy(logits, labels):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == labels).float().mean().item() * 100\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            acc_sum += accuracy(model(x), y) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    return acc_sum / n\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = FoodCNN(num_classes).to(device)\n",
    "\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "optimizer  = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler  = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
    "\n",
    "best = 0.0\n",
    "for epoch in range(1, 21):\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        loss = criterion(model(x), y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_acc = evaluate(model, test_loader)\n",
    "    print(f\"epoch {epoch:02d} | test acc {test_acc:.2f}%\")\n",
    "\n",
    "    if test_acc > best:\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        best = test_acc\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb476e18bd30968c",
   "metadata": {},
   "source": [
    "# Calculating model performance\n",
    "Load the best version of your model ( which should be produced and saved by previous cells ), calculate and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa35096547d04",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid device string: 'best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the best model weights\u001b[39;00m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mFoodCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m final_test_acc \u001b[38;5;241m=\u001b[39m calculate_test_accuracy(model)\n",
      "File \u001b[1;32mc:\\Users\\pepij\\anaconda3\\envs\\foodcnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1302\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m    This can be called as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1302\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype\u001b[38;5;241m.\u001b[39mis_floating_point \u001b[38;5;129;01mor\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mis_complex):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Invalid device string: 'best_model.pth'"
     ]
    }
   ],
   "source": [
    "# Load the best model weights\n",
    "model = FoodCNN(num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "final_test_acc = calculate_test_accuracy(model)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecc6f7f921591e",
   "metadata": {},
   "source": [
    "# Summary of hyperparameters\n",
    "Report the hyperparameters ( learning rate etc ) that you used in your final model for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6a524e28b431a",
   "metadata": {},
   "source": [
    "# Simulation of random user\n",
    "Pick 10 random pictures of the test set to simulate a user uploading images and report which categories occur how often in these: 1pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8175cacc8dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T17:04:06.539916Z",
     "start_time": "2025-04-02T17:04:05.929092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Below an example showing the format of the code output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7a3634bf6861f",
   "metadata": {},
   "source": [
    "# Bonus point\n",
    "Use an LLM (API) to generate a description of the food preference of a user based on 10 images that a potential user could provide. \n",
    "Please include an example of the output of your code, especially if you used an API other than the OpenAI API.\n",
    "\n",
    "This should work well even with differing test images by setting different random seeds for the image selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819fa0042485dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
